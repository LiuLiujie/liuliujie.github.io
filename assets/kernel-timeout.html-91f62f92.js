import{_ as t}from"./plugin-vue_export-helper-c27b6911.js";import{r as o,o as p,c,a as n,b as s,e,d as l}from"./app-9e8a13db.js";const i={},u=n("h1",{id:"how-to-stop-a-running-cuda-kernel-when-timeout",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#how-to-stop-a-running-cuda-kernel-when-timeout","aria-hidden":"true"},"#"),s(" How to stop a running CUDA kernel (when timeout)")],-1),r=n("p",null,"When we start a CUDA kernel, it just runs like the Rud Bull racing car and can never be stopped before the kernel finishes. However, we need a timeout machenism to stop the kernel when the the kernel goes to an infinite loop or deadlock. However, the NVIDIA doesn't offer a way to stop the kernel in a decent way, which is especially required when I am doing mutation testing on CUDA kernel.",-1),d=n("p",null,"This article will record the steps I tried to reach the final result. Some of the directions or methods work, some doesn't, and some works but not work that good.",-1),k=n("p",null,[s("I come up with "),n("strong",null,"2 directions"),s(" and try to deal with this problem.")],-1),h=n("h2",{id:"direction-1-let-the-kernel-kill-itself-when-timeout",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#direction-1-let-the-kernel-kill-itself-when-timeout","aria-hidden":"true"},"#"),s(" Direction 1: Let the kernel kill itself when timeout")],-1),m={href:"https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__DEVICE.html#group__CUDART__DEVICE_1gef69dd5c6d0206c2b8d099abac61f217",target:"_blank",rel:"noopener noreferrer"},v=n("code",null,"cudaDeviceReset()",-1),b=n("h3",{id:"app-1-copy-a-interrupt-flag-to-the-running-kernel-in-runtime-when-timeout",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#app-1-copy-a-interrupt-flag-to-the-running-kernel-in-runtime-when-timeout","aria-hidden":"true"},"#"),s(" App 1: Copy a "),n("code",null,"interrupt"),s(" flag to the running kernel in runtime when timeout.")],-1),w={href:"https://stackoverflow.com/questions/12505750/how-can-a-global-function-return-a-value-or-break-out-like-c-c-does/12506030#12506030",target:"_blank",rel:"noopener noreferrer"},f=l(`<div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token comment">//Use volatile here to avoid compiler optimization and make sure that the threads in the while loop will always read the interrupt parameter for each iteration.</span>
__global___ <span class="token keyword">void</span> <span class="token function">kernel</span><span class="token punctuation">(</span><span class="token keyword">volatile</span> bool <span class="token operator">*</span>interrupt<span class="token punctuation">)</span> 
<span class="token punctuation">{</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span>true<span class="token punctuation">)</span> <span class="token punctuation">{</span>
			<span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">*</span>interrupt<span class="token punctuation">)</span><span class="token punctuation">{</span>
        <span class="token keyword">return</span><span class="token punctuation">;</span> <span class="token comment">// or directly asm(&quot;trap;&quot;);</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>The idea looks nice, but to achieve this we need to solve two problems.</p><h4 id="p1-how-to-copy-the-interrupt-flag-from-host-to-device-in-the-runtime" tabindex="-1"><a class="header-anchor" href="#p1-how-to-copy-the-interrupt-flag-from-host-to-device-in-the-runtime" aria-hidden="true">#</a> P1: How to copy the interrupt flag from host to device in the runtime?</h4><ol><li><p>Single Stream ❌: Both sync call <code>cudaMemcpy()</code> and async call <code>cudaMemcpyAsync()</code> cannot pass the flag successfully because the CUDA will implicitly synchronize before the kernel start (force the async call finish), and all the copy jobs after the kernel starts will not be sent to the kennel.</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code><span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_x<span class="token punctuation">,</span> x<span class="token punctuation">,</span> N<span class="token operator">*</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_y<span class="token punctuation">,</span> y<span class="token punctuation">,</span> N<span class="token operator">*</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">//Set the interrupt flag to false so that the kernel can run</span>
<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>d_z<span class="token punctuation">,</span> z<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>bool<span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">//An implicit sycronization call happens here</span>

<span class="token comment">//Start the kernel</span>
saxpy<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">(</span>N<span class="token operator">+</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">2.0f</span><span class="token punctuation">,</span> d_x<span class="token punctuation">,</span> d_y<span class="token punctuation">,</span> d_z<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// Copy the interrupt flag, this will not be done before the kernel finish.</span>
<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>d_z<span class="token punctuation">,</span> z<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>bool<span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li><li><p>Multiple Stream ✅:</p><ul><li><p>I also tried this using CUDA-C.</p><ul><li><p><strong>In miltiple stream.</strong> If we do want to set a stream’s device memory in another stream, like the code below, where the killer kernel try to change the value of the flag in device memory. However, this will make the whole stream goes into a dead lock and the kernels cannot be stoped.</p><div class="language-c line-numbers-mode" data-ext="c"><pre class="language-c"><code>__global__ <span class="token keyword">void</span> <span class="token function">killer</span><span class="token punctuation">(</span><span class="token keyword">volatile</span> bool <span class="token operator">*</span>interrupt<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">//It takes about 2s to run in my RTX3050</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>threadIdx<span class="token punctuation">.</span>x <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10000000</span><span class="token punctuation">;</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>interrupt<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
                i<span class="token operator">=</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
        interrupt<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>d_x<span class="token punctuation">,</span> x<span class="token punctuation">,</span> N<span class="token operator">*</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">,</span> stream<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>d_y<span class="token punctuation">,</span> y<span class="token punctuation">,</span> N<span class="token operator">*</span><span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">,</span> stream<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>d_z<span class="token punctuation">,</span> z<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>bool<span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">,</span> stream<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
saxpy<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token punctuation">(</span>N<span class="token operator">+</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> stream<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">2.0f</span><span class="token punctuation">,</span> d_x<span class="token punctuation">,</span> d_y<span class="token punctuation">,</span> d_z<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>d_z<span class="token punctuation">,</span> z<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>bool<span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">,</span> stream<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">// Trigger dead lock</span>
killer<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> stream<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_z<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">cudaMemcpyAsync</span><span class="token punctuation">(</span>z<span class="token punctuation">,</span> d_z<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>bool<span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">,</span> stream<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div></li></ul></li></ul></li><li><p>Use <strong>pagelocked memory</strong>, which will lock the part of host memory and prevent it from be swapped out. At this case we always know the address of memory and can copy from it to GPU.</p></li><li><p><strong>Unified memory</strong> (managed memory) : the CUDA driver will do most of the memory allocation and copy job. As a programmer it looks like the CPU and GPU directly share a memory.</p><p>At first I thought it not work because the CUDA guidance says it is not allowed to modify the unified memory on host side during the kernel runtime, the kernel will directly crash. However, later I found that on Pascal and later GPUs, the CPU and the GPU can simultaneously access managed memory.</p></li></ol><h4 id="p2-how-to-make-sure-that-all-threads-will-return-or-at-least-one-thread-will-go-to-the-trap" tabindex="-1"><a class="header-anchor" href="#p2-how-to-make-sure-that-all-threads-will-return-or-at-least-one-thread-will-go-to-the-trap" aria-hidden="true">#</a> P2: How to make sure that all threads will <code>return</code>, or at least one thread will go to the <code>trap</code>?</h4><p>There are 2 situation need to consider:</p><ul><li><p>All threads were trapped into the same infinite loop or different infinite loops (if any): The interrupt <code>if</code> statement need to be inserted into every <code>while</code> and <code>for</code> loop to make sure that at least one thread will reach the statement.</p></li><li><p>At least one thread can break the loop and go to the end of the kernel, and we need that thread to wait there until 1) we reach the threshold and we interrupt, or 2) all threads can come to end properly and we make a return.</p></li></ul><h3 id="app-2-set-a-timer-for-each-thread-and-let-the-thread-trap-the-kernel-when-reaching-the-timeout-threshold" tabindex="-1"><a class="header-anchor" href="#app-2-set-a-timer-for-each-thread-and-let-the-thread-trap-the-kernel-when-reaching-the-timeout-threshold" aria-hidden="true">#</a> App 2: Set a timer for each thread and let the thread trap the kernel when reaching the timeout threshold</h3><ul><li>I just come up with this idea and do some Google search, but I didn&#39;t try it.</li><li>There is no timer on GPUs like the one on CPUs. The running time needs to be calculated based on the frequency of the GPU using a runtime API called <code>clock()</code></li><li>We still need to make sure that all threads will go to return or at least one thread will go to the trap. So the the <code>clock()</code> also needs to be set up in every loop.</li><li>It is not that decent because you need to check the clock many times and will slow down the exection. The <code>clock()</code> also return a <code>long long</code> type which is big but still have overflow possibility when the kernel execution time is also long.</li></ul><h2 id="direction-2-kill-the-host-side-process-to-let-the-gpu-driver-kill-the-corresponding-device-process" tabindex="-1"><a class="header-anchor" href="#direction-2-kill-the-host-side-process-to-let-the-gpu-driver-kill-the-corresponding-device-process" aria-hidden="true">#</a> Direction 2: Kill the host side process to let the GPU driver kill the corresponding device process</h2><p>When killing the python process, the corresponding GPU process will also be killed by the GPU driver and the occupied CUDA resources will also be released.</p><p>I managed to achieve this direction.</p><ul><li>Firstly I try to using thread instead of process because thread is lighter than process. However, killing a thread will not cause the kernel stop becuase the kernel is binded with the process. Then I have to use child process and it works</li><li>All the kernel context (pycuda context in our case) need to be initialized within the child process</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">TerminableMutantRunner</span><span class="token punctuation">(</span>multiprocessing<span class="token punctuation">.</span>Process<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># A new process is started for each mutant with all the test cases. Which means:</span>
  <span class="token comment">#		1. The mutant will be compiled only once. (The most time comsuming job)</span>
 	<span class="token comment">#			 If the compilation fail the process will return een error.		</span>
  <span class="token comment">#   2. We interate the test cases and update the GPU arguments</span>
  <span class="token comment">#   3. We return resutls for all the test cases to main process and verify the results there,</span>
  <span class="token comment"># 		 or the killer will be started when a test case timeout and this process itself will be killed</span>
  
  
	<span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kernel_builder<span class="token punctuation">:</span> TestingKernelBuilder<span class="token punctuation">,</span> mutant<span class="token punctuation">:</span> Mutant<span class="token punctuation">,</span> test_cases<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">[</span>TestCase<span class="token punctuation">]</span><span class="token punctuation">,</span>
                  result_queue<span class="token punctuation">,</span> exception_queue<span class="token punctuation">)</span><span class="token punctuation">:</span> 
  
  <span class="token keyword">def</span> <span class="token function">terminate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> exception_cls<span class="token punctuation">,</span> repeat_sec<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">if</span> self<span class="token punctuation">.</span>is_alive<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token boolean">False</span><span class="token punctuation">:</span>
          <span class="token keyword">return</span> <span class="token boolean">True</span>
      killer <span class="token operator">=</span> MutantRunnerKiller<span class="token punctuation">(</span>self<span class="token punctuation">,</span> exception_cls<span class="token punctuation">,</span> repeat_sec<span class="token operator">=</span>repeat_sec<span class="token punctuation">)</span>
      killer<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">MutantRunnerKiller</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>Thread<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># This is called by the process itself when the mutant execution timeout and </span>

  <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">while</span> self<span class="token punctuation">.</span>target_process<span class="token punctuation">.</span>is_alive<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            os<span class="token punctuation">.</span>kill<span class="token punctuation">(</span>self<span class="token punctuation">.</span>target_process<span class="token punctuation">.</span>pid<span class="token punctuation">,</span> signal<span class="token punctuation">.</span>SIGKILL<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>target_process<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>repeat_sec<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,14);function y(g,_){const a=o("ExternalLinkIcon");return p(),c("div",null,[u,r,d,k,h,n("p",null,[s("Automatically generating an interruptions mechanism in kernel code to let the kernel kill itself (e.g. calling CUDA runtime API "),n("a",m,[v,e(a)]),s(" when timeout).")]),b,n("p",null,[s("This method was hinted by a Stackoverflow "),n("a",w,[s("answer"),e(a)]),s(" and the hint from my supervisor. We can try to send a boolean value to the device memory when the timer expires. Just like the kernel code below.")]),f])}const T=t(i,[["render",y],["__file","kernel-timeout.html.vue"]]);export{T as default};
